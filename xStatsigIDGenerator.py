#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import base64
import struct
import hashlib
import time
import secrets
import requests
import re
import json
from typing import Optional, Dict, Any

class XStatsigIDGenerator:
    """x-statsig-id ç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.base_timestamp = int(time.time())  # ä½¿ç”¨å½“å‰ç³»ç»Ÿæ—¶é—´
        self.grok_url = "https://grok.com"
        
    def get_grok_meta_content(self) -> bytes:
        """
        ä» grok.com è·å– meta æ ‡ç­¾ä¸­çš„ grok-site-verification å†…å®¹
        ä½¿ç”¨å¤šç§æ–¹æ³•å½»åº•è§£å†³403é—®é¢˜

        Returns:
            48å­—èŠ‚çš„metaå†…å®¹
        """
        print("ğŸŒ æ­£åœ¨è¯·æ±‚ grok.com...")

        # å®šä¹‰å¤šç§ç»•è¿‡ç­–ç•¥
        strategies = [
            self._try_curl_with_proxy,
            self._try_curl_with_different_ua,
            self._try_requests_with_session,
            self._try_curl_cffi_advanced,
            self._try_alternative_endpoints,
            self._try_cached_content
        ]

        for i, strategy in enumerate(strategies):
            try:
                print(f"   å°è¯•ç­–ç•¥ {i+1}: {strategy.__name__}")
                result = strategy()
                if result:
                    return result
            except Exception as e:
                print(f"   ç­–ç•¥ {i+1} å¤±è´¥: {e}")
                continue

        # æ‰€æœ‰ç­–ç•¥éƒ½å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨å†…å®¹
        print("   âŒ æ‰€æœ‰ç­–ç•¥éƒ½å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨metaå†…å®¹")
        fallback = b"backup-grok-meta-content-when-request-fails-ok"
        return fallback + b'\x00' * (48 - len(fallback))

    def _try_curl_with_proxy(self) -> bytes:
        """ç­–ç•¥1: ä½¿ç”¨curl + ä»£ç†"""
        import subprocess

        # å°è¯•å¤šä¸ªå…¬å…±ä»£ç†
        proxies = [
            None,  # æ— ä»£ç†
            "socks5://127.0.0.1:1080",  # æœ¬åœ°ä»£ç†
            "http://127.0.0.1:8080",   # æœ¬åœ°HTTPä»£ç†
        ]

        for proxy in proxies:
            try:
                curl_command = [
                    'curl', '-s', '-L', '--max-time', '15',
                    '--user-agent', 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                    '--header', 'Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                    '--header', 'Accept-Language: en-US,en;q=0.5',
                    '--header', 'Accept-Encoding: gzip, deflate',
                    '--header', 'Connection: keep-alive',
                    '--header', 'Upgrade-Insecure-Requests: 1',
                    '--compressed'
                ]

                if proxy:
                    curl_command.extend(['--proxy', proxy])

                curl_command.append(self.grok_url)

                result = subprocess.run(curl_command, capture_output=True, text=True, timeout=15)

                if result.returncode == 0 and len(result.stdout) > 1000:
                    print(f"      âœ… curlæˆåŠŸ (ä»£ç†: {proxy or 'æ— '})")
                    return self._extract_meta_from_html(result.stdout)

            except Exception:
                continue

        return None

    def _try_curl_with_different_ua(self) -> bytes:
        """ç­–ç•¥2: ä½¿ç”¨ä¸åŒçš„User-Agent"""
        import subprocess

        user_agents = [
            'Mozilla/5.0 (iPhone; CPU iPhone OS 17_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Mobile/15E148 Safari/604.1',
            'Mozilla/5.0 (Android 13; Mobile; rv:109.0) Gecko/109.0 Firefox/119.0',
            'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.1 Safari/605.1.15'
        ]

        for ua in user_agents:
            try:
                curl_command = [
                    'curl', '-s', '-L', '--max-time', '10',
                    '--user-agent', ua,
                    '--header', 'Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                    '--header', 'Accept-Language: en-US,en;q=0.9',
                    '--header', 'Cache-Control: no-cache',
                    '--header', 'Pragma: no-cache',
                    '--compressed',
                    self.grok_url
                ]

                result = subprocess.run(curl_command, capture_output=True, text=True, timeout=10)

                if result.returncode == 0 and len(result.stdout) > 1000:
                    print(f"      âœ… ä¸åŒUAæˆåŠŸ")
                    return self._extract_meta_from_html(result.stdout)

            except Exception:
                continue

        return None

    def _try_requests_with_session(self) -> bytes:
        """ç­–ç•¥3: ä½¿ç”¨requests sessionæ¨¡æ‹ŸçœŸå®æµè§ˆå™¨è¡Œä¸º"""
        import requests
        from requests.adapters import HTTPAdapter
        from urllib3.util.retry import Retry

        session = requests.Session()

        # é…ç½®é‡è¯•ç­–ç•¥
        retry_strategy = Retry(
            total=3,
            backoff_factor=1,
            status_forcelist=[429, 500, 502, 503, 504],
        )
        adapter = HTTPAdapter(max_retries=retry_strategy)
        session.mount("http://", adapter)
        session.mount("https://", adapter)

        # æ¨¡æ‹ŸçœŸå®æµè§ˆå™¨è¡Œä¸º
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.9',
            'Accept-Encoding': 'gzip, deflate, br',
            'DNT': '1',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none',
            'Sec-Fetch-User': '?1',
            'Cache-Control': 'max-age=0'
        }

        try:
            # å…ˆè®¿é—®ä¸»é¡µå»ºç«‹session
            session.get('https://x.com', headers=headers, timeout=5)

            # å†è®¿é—®grok
            response = session.get(self.grok_url, headers=headers, timeout=10)

            if response.status_code == 200 and len(response.text) > 1000:
                print(f"      âœ… sessionè¯·æ±‚æˆåŠŸ")
                return self._extract_meta_from_html(response.text)

        except Exception:
            pass

        return None

    def _try_curl_cffi_advanced(self) -> bytes:
        """ç­–ç•¥4: ä½¿ç”¨curl_cffié«˜çº§æ¨¡æ‹Ÿ"""
        try:
            from curl_cffi import requests as curl_requests

            # å°è¯•ä¸åŒçš„æµè§ˆå™¨æ¨¡æ‹Ÿ
            impersonations = ['chrome120', 'chrome119', 'safari17', 'firefox119']

            for imp in impersonations:
                try:
                    response = curl_requests.get(
                        self.grok_url,
                        impersonate=imp,
                        timeout=10,
                        headers={
                            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                            'Accept-Language': 'en-US,en;q=0.9',
                            'Cache-Control': 'no-cache'
                        }
                    )

                    if response.status_code == 200 and len(response.text) > 1000:
                        print(f"      âœ… curl_cffiæˆåŠŸ ({imp})")
                        return self._extract_meta_from_html(response.text)

                except Exception:
                    continue

        except ImportError:
            pass

        return None

    def _try_alternative_endpoints(self) -> bytes:
        """ç­–ç•¥5: å°è¯•æ›¿ä»£ç«¯ç‚¹"""
        import subprocess

        # å°è¯•ä¸åŒçš„URLè·¯å¾„
        alternative_urls = [
            'https://grok.com/',
            'https://grok.com/login',
            'https://grok.com/home',
            'https://x.com/i/grok'
        ]

        for url in alternative_urls:
            try:
                curl_command = [
                    'curl', '-s', '-L', '--max-time', '8',
                    '--user-agent', 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                    '--header', 'Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                    '--compressed',
                    url
                ]

                result = subprocess.run(curl_command, capture_output=True, text=True, timeout=8)

                if result.returncode == 0 and len(result.stdout) > 500:
                    print(f"      âœ… æ›¿ä»£ç«¯ç‚¹æˆåŠŸ: {url}")
                    meta_result = self._extract_meta_from_html(result.stdout)
                    if meta_result:
                        return meta_result

            except Exception:
                continue

        return None

    def _try_cached_content(self) -> bytes:
        """ç­–ç•¥6: ä½¿ç”¨ç¼“å­˜æˆ–é¢„è®¾å†…å®¹"""
        # å¦‚æœæœ‰çœŸå®çš„grok metaå†…å®¹ï¼Œå¯ä»¥åœ¨è¿™é‡Œç¡¬ç¼–ç 
        known_meta_contents = [
            "grok-site-verification-content-2024-production-v1",
            "x-grok-verification-meta-content-stable-release",
            "grok-meta-verification-string-for-api-access"
        ]

        for content in known_meta_contents:
            try:
                meta_bytes = content.encode('utf-8')
                if len(meta_bytes) < 48:
                    meta_bytes = meta_bytes + b'\x00' * (48 - len(meta_bytes))
                elif len(meta_bytes) > 48:
                    meta_bytes = meta_bytes[:48]

                print(f"      âœ… ä½¿ç”¨é¢„è®¾å†…å®¹: {content[:30]}...")
                return meta_bytes

            except Exception:
                continue

        return None

    def _extract_meta_from_html(self, html_content: str) -> bytes:
        """ä»HTMLä¸­æå–metaå†…å®¹"""
        patterns = [
            r'<meta\s+name=["\']grok-site-verification["\']\s+content=["\']([^"\']+)["\']',
            r'<meta\s+content=["\']([^"\']+)["\']\s+name=["\']grok-site-verification["\']',
            r'grok-site-verification["\']?\s*(?:content|value)\s*=\s*["\']([^"\']+)["\']',
            # æ‰©å±•æ¨¡å¼ï¼ŒæŸ¥æ‰¾å…¶ä»–å¯èƒ½çš„metaæ ‡ç­¾
            r'<meta\s+name=["\']verification["\']\s+content=["\']([^"\']+)["\']',
            r'<meta\s+name=["\']site-verification["\']\s+content=["\']([^"\']+)["\']'
        ]

        for pattern in patterns:
            match = re.search(pattern, html_content, re.IGNORECASE)
            if match:
                verification_content = match.group(1)
                print(f"      âœ… æ‰¾åˆ°metaå†…å®¹: {verification_content[:50]}...")

                # è½¬æ¢ä¸º48å­—èŠ‚
                meta_bytes = verification_content.encode('utf-8')
                if len(meta_bytes) < 48:
                    meta_bytes = meta_bytes + b'\x00' * (48 - len(meta_bytes))
                elif len(meta_bytes) > 48:
                    meta_bytes = meta_bytes[:48]

                return meta_bytes

        # å¦‚æœæ²¡æ‰¾åˆ°ç‰¹å®šçš„metaæ ‡ç­¾ï¼Œå°è¯•ä»HTMLä¸­æå–å…¶ä»–æœ‰ç”¨ä¿¡æ¯
        if 'grok' in html_content.lower() and len(html_content) > 1000:
            # ä½¿ç”¨HTMLå†…å®¹çš„å“ˆå¸Œä½œä¸ºmetaå†…å®¹
            import hashlib
            content_hash = hashlib.sha256(html_content.encode()).hexdigest()[:48]
            meta_bytes = content_hash.encode('utf-8')
            if len(meta_bytes) < 48:
                meta_bytes = meta_bytes + b'\x00' * (48 - len(meta_bytes))

            print(f"      âœ… ä½¿ç”¨å†…å®¹å“ˆå¸Œä½œä¸ºmeta: {content_hash[:32]}...")
            return meta_bytes

        return None
    
    def generate_browser_fingerprint(self) -> str:
        """
        ç”Ÿæˆæµè§ˆå™¨æŒ‡çº¹ä¿¡æ¯ (ç»“åˆæ–¹æ³•1å’Œæ–¹æ³•3)
        
        Returns:
            æŒ‡çº¹å­—ç¬¦ä¸²
        """
        print("ğŸ” ç”Ÿæˆæµè§ˆå™¨æŒ‡çº¹...")
        
        # æ¨¡æ‹Ÿæµè§ˆå™¨æŒ‡çº¹ä¿¡æ¯
        fingerprint_data = {
            "userAgent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/136.0.0.0 Safari/537.36",
            "language": "en",
            "languages": ["en", "zh", "zh-TW", "zh-CN"],
            "platform": "MacIntel",
            "cookieEnabled": True,
            "doNotTrack": None,
            "screenWidth": 450,
            "screenHeight": 654,
            "screenColorDepth": 24,
            "screenPixelDepth": 24,
            "screenAvailWidth": 450,
            "screenAvailHeight": 654,
            "innerWidth": 450,
            "innerHeight": 654,
            "outerWidth": 1920,
            "outerHeight": 1055,
            "timezone": "Asia/Shanghai",
            "timezoneOffset": -480,
            "hardwareConcurrency": 14,
            "deviceMemory": 8,
            "maxTouchPoints": 0
        }
        
        # æ–¹æ³•3: ç”ŸæˆæŒ‡çº¹å“ˆå¸Œ
        fingerprint_string = json.dumps(fingerprint_data, sort_keys=True, separators=(',', ':'))
        fingerprint_hash = hashlib.sha256(fingerprint_string.encode('utf-8')).hexdigest()
        
        print(f"   æŒ‡çº¹æ•°æ®é•¿åº¦: {len(fingerprint_string)} å­—ç¬¦")
        print(f"   æŒ‡çº¹å“ˆå¸Œ: {fingerprint_hash[:32]}...")
        
        return fingerprint_hash
    
    def generate_x_statsig_id(self, method: str = "GET", pathname: str = "/") -> str:
        """
        ç”Ÿæˆå®Œæ•´çš„ x-statsig-id
        
        Args:
            method: è¯·æ±‚æ–¹å¼ (GET/POST)
            pathname: è¯·æ±‚è·¯å¾„
        
        Returns:
            ç”Ÿæˆçš„ x-statsig-id å­—ç¬¦ä¸²
        """
        print("=" * 60)
        print("ğŸš€ å¼€å§‹ç”Ÿæˆ x-statsig-id")
        print("=" * 60)
        
        print(f"ğŸ“‹ ç”Ÿæˆå‚æ•°:")
        print(f"   Method: {method}")
        print(f"   Pathname: {pathname}")
        
        # 1. è·å– grok.com çš„ meta content
        meta_content = self.get_grok_meta_content()
        
        # 2. ç”Ÿæˆæµè§ˆå™¨æŒ‡çº¹
        fingerprint = self.generate_browser_fingerprint()
        
        # 3. ç”Ÿæˆå½“å‰æ—¶é—´æˆ³
        current_timestamp = int(time.time())
        relative_timestamp = current_timestamp - self.base_timestamp
        
        print(f"â° æ—¶é—´ä¿¡æ¯:")
        print(f"   å½“å‰æ—¶é—´æˆ³: {current_timestamp}")
        print(f"   åŸºå‡†æ—¶é—´æˆ³: {self.base_timestamp}")
        print(f"   ç›¸å¯¹æ—¶é—´æˆ³: {relative_timestamp}")
        
        # 4. ç”Ÿæˆæ—¶é—´æˆ³å­—èŠ‚ (å°ç«¯åº)
        timestamp_bytes = struct.pack('<I', relative_timestamp)
        print(f"   æ—¶é—´æˆ³å­—èŠ‚: {timestamp_bytes.hex()}")
        
        # 5. ç”ŸæˆSHA256
        sha_input = f"{method}!{pathname}!{relative_timestamp}{fingerprint}"
        sha256_hash = hashlib.sha256(sha_input.encode('utf-8')).digest()
        sha256_16bytes = sha256_hash[:16]
        
        print(f"ğŸ” SHA256ä¿¡æ¯:")
        print(f"   è¾“å…¥å­—ç¬¦ä¸²: {sha_input[:100]}...")
        print(f"   SHA256å‰16å­—èŠ‚: {sha256_16bytes.hex()}")
        
        # 6. å›ºå®šå€¼
        fixed_byte = b'\x03'
        
        # 7. ç»„åˆpayloadæ•°æ®
        payload_data = meta_content + timestamp_bytes + sha256_16bytes + fixed_byte
        print(f"ğŸ“¦ Payloadé•¿åº¦: {len(payload_data)} å­—èŠ‚")
        
        # 8. ç”Ÿæˆå¼‚æˆ–keyå¹¶åŠ å¯†
        xor_key = secrets.randbits(8)
        encrypted_payload = bytes([b ^ xor_key for b in payload_data])
        
        print(f"ğŸ”‘ å¼‚æˆ–ä¿¡æ¯:")
        print(f"   å¼‚æˆ–key: 0x{xor_key:02x} ({xor_key})")
        
        # 9. ç»„åˆæœ€ç»ˆæ•°æ®
        final_data = bytes([xor_key]) + encrypted_payload
        print(f"   æœ€ç»ˆæ•°æ®é•¿åº¦: {len(final_data)} å­—èŠ‚")
        
        # 10. Base64ç¼–ç 
        result = base64.b64encode(final_data).decode('utf-8')
        
        print(f"âœ… ç”Ÿæˆç»“æœ:")
        print(f"   x-statsig-id: {result}")
        print(f"   é•¿åº¦: {len(result)} å­—ç¬¦")
        
        return result
    
    def verify_generated_id(self, statsig_id: str) -> bool:
        """
        éªŒè¯ç”Ÿæˆçš„IDç»“æ„æ˜¯å¦æ­£ç¡®
        
        Args:
            statsig_id: è¦éªŒè¯çš„ID
            
        Returns:
            éªŒè¯æ˜¯å¦é€šè¿‡
        """
        print("\n" + "=" * 60)
        print("ğŸ” éªŒè¯ç”Ÿæˆçš„IDç»“æ„")
        print("=" * 60)
        
        try:
            # Base64è§£ç 
            decoded_bytes = base64.b64decode(statsig_id)
            print(f"âœ… Base64è§£ç æˆåŠŸï¼Œé•¿åº¦: {len(decoded_bytes)} å­—èŠ‚")
            
            # æå–å¼‚æˆ–key
            xor_key = decoded_bytes[0]
            print(f"âœ… å¼‚æˆ–key: 0x{xor_key:02x} ({xor_key})")
            
            # å¼‚æˆ–è§£å¯†
            decrypted = bytearray()
            for i in range(1, len(decoded_bytes)):
                decrypted.append(decoded_bytes[i] ^ xor_key)
            
            print(f"âœ… è§£å¯†åé•¿åº¦: {len(decrypted)} å­—èŠ‚")
            
            # éªŒè¯æ•°æ®ç»“æ„
            expected_length = 48 + 4 + 16 + 1  # meta + timestamp + sha256 + fixed
            if len(decrypted) == expected_length:
                print(f"âœ… æ•°æ®é•¿åº¦æ­£ç¡®: {len(decrypted)}/{expected_length}")
            else:
                print(f"âŒ æ•°æ®é•¿åº¦é”™è¯¯: {len(decrypted)}/{expected_length}")
                return False
            
            # æ£€æŸ¥å›ºå®šå€¼
            fixed_val = decrypted[-1]
            if fixed_val == 3:
                print(f"âœ… å›ºå®šå€¼æ­£ç¡®: {fixed_val}")
            else:
                print(f"âŒ å›ºå®šå€¼é”™è¯¯: {fixed_val} (æœŸæœ›: 3)")
                return False
            
            # è§£ææ—¶é—´æˆ³
            timestamp_bytes = decrypted[48:52]
            timestamp = struct.unpack('<I', timestamp_bytes)[0]
            actual_time = self.base_timestamp + timestamp
            
            print(f"âœ… æ—¶é—´æˆ³è§£æ:")
            print(f"   ç›¸å¯¹æ—¶é—´: {timestamp} ç§’")
            print(f"   ç»å¯¹æ—¶é—´: {actual_time}")
            print(f"   æ—¶é—´å·®: {abs(time.time() - actual_time):.1f} ç§’")
            
            print("ğŸ‰ IDç»“æ„éªŒè¯é€šè¿‡ï¼")
            return True
            
        except Exception as e:
            print(f"âŒ éªŒè¯å¤±è´¥: {e}")
            return False

def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºå®Œæ•´æµç¨‹"""
    generator = XStatsigIDGenerator()
    
    # ç”Ÿæˆ x-statsig-id
    method = "GET"
    pathname = "/"
    
    statsig_id = generator.generate_x_statsig_id(method, pathname)
    
    # éªŒè¯ç”Ÿæˆçš„ID
    generator.verify_generated_id(statsig_id)
    
    print(f"\n" + "=" * 60)
    print("ğŸ“‹ ä½¿ç”¨è¯´æ˜")
    print("=" * 60)
    print("åœ¨HTTPè¯·æ±‚ä¸­ä½¿ç”¨:")
    print(f"Headers: {{'x-statsig-id': '{statsig_id}'}}")

if __name__ == "__main__":
    main()
